{'summarized_nodes': [{'title': 'Markov chain Monte Carlo', 'summary': 'A statistical method used to approximate the posterior distribution of a model, foundational in Bayesian statistics and MCMC methods.', 'original_ids': ['Markov chain Monte Carlo', 'Robert and Casella', 'Bayesian statistics'], 'type': 'Algorithm', 'keywords': ['MCMC', 'Bayesian', 'posterior distribution']}, {'title': 'hLDA', 'summary': 'Hierarchical Latent Dirichlet Allocation, a generative model for topic modeling that analyzes document collections to discover and visualize hierarchies.', 'original_ids': ['hLDA', 'hLDA model'], 'type': 'Model', 'keywords': ['topic modeling', 'hierarchical', 'Dirichlet']}, {'title': 'latent topic structure', 'summary': 'The hidden structure representing topics within a document collection, inferred from observed documents.', 'original_ids': ['latent topic structure', 'hidden structure'], 'type': 'Concept', 'keywords': ['latent', 'topics', 'structure']}, {'title': 'observed documents', 'summary': 'Documents that are analyzed to infer the latent topic structure, conditioned on hidden variables.', 'original_ids': ['observed documents', 'documents'], 'type': 'Data', 'keywords': ['documents', 'analysis', 'inference']}, {'title': 'posterior distribution', 'summary': 'The distribution of the hidden structure after observing the data, crucial in Bayesian statistics.', 'original_ids': ['posterior distribution', 'posterior'], 'type': 'Concept', 'keywords': ['posterior', 'Bayesian', 'distribution']}, {'title': 'hyperparameters', 'summary': 'Settings that influence the behavior of models like hLDA, determined prior to analysis.', 'original_ids': ['hyperparameters', 'Dirichlet parameter', 'stick-breaking parameters'], 'type': 'Parameter', 'keywords': ['hyperparameters', 'model behavior', 'settings']}, {'title': 'Subtopics', 'summary': 'Specific themes or topics that arise within a corpus, allowing for the discovery of new insights.', 'original_ids': ['Subtopics'], 'type': 'Concept', 'keywords': ['subtopics', 'themes', 'corpus']}, {'title': 'dynamic topic model', 'summary': 'A topic model that incorporates time-stamped documents and evolving topics.', 'original_ids': ['dynamic topic model'], 'type': 'Model', 'keywords': ['dynamic', 'topic model', 'time-stamped']}, {'title': 'Gibbs sampling', 'summary': 'A statistical method used for sampling from probability distributions based on constructing a Markov chain.', 'original_ids': ['Gibbs sampler', 'collapsed Gibbs sampling'], 'type': 'Algorithm', 'keywords': ['Gibbs sampling', 'MCMC', 'sampling']}, {'title': 'Bayesian nonparametric model', 'summary': 'A statistical model that can accommodate future data, allowing for flexibility in analysis.', 'original_ids': ['Bayesian nonparametric model'], 'type': 'Model', 'keywords': ['Bayesian', 'nonparametric', 'future data']}, {'title': 'document categories', 'summary': 'Methods and algorithms for categorizing documents within a hierarchy, developed by various researchers.', 'original_ids': ['document categories', 'Koller and Sahami', 'Chakrabarti et al.', 'McCallum et al.', 'Dumais and Chen'], 'type': 'Concept', 'keywords': ['document categorization', 'hierarchy', 'algorithms']}], 'summarized_relationships': [{'source': 'Markov chain Monte Carlo', 'target': 'hLDA', 'relation_type': 'USED_IN', 'weight': 2, 'original_relationships': ['Markov chain Monte Carlo->hLDA(Used to approximate the posterior for)', 'hLDA->Markov chain Monte Carlo(Target of approximation by)']}, {'source': 'hLDA', 'target': 'latent topic structure', 'relation_type': 'ANALYZES', 'weight': 2, 'original_relationships': ['hLDA->latent topic structure(Combined with to form a joint distribution)', 'latent topic structure->observed documents(Is related to)']}, {'source': 'latent topic structure', 'target': 'observed documents', 'relation_type': 'INFERRED_FROM', 'weight': 2, 'original_relationships': ['latent topic structure->observed documents(Combined with to form a joint distribution)', 'observed documents->latent topic structure(Is related to)']}, {'source': 'posterior distribution', 'target': 'hyperparameters', 'relation_type': 'DERIVED_FROM', 'weight': 2, 'original_relationships': ['posterior distribution->hyperparameters(Computed through posterior inference)', 'hyperparameters->posterior(Determines how they are set)']}, {'source': 'Subtopics', 'target': 'dynamic topic model', 'relation_type': 'USED_IN', 'weight': 1, 'original_relationships': ['Subtopics->dynamic topic model(Models)', 'dynamic topic model->Subtopics(Used in)']}, {'source': 'Gibbs sampling', 'target': 'document categories', 'relation_type': 'APPLIED_IN', 'weight': 3, 'original_relationships': ['Gibbs sampling->document categories(Developed methods for placing documents within a hierarchy)', 'collapsed Gibbs sampling->document categories(Contributed to methods for categorizing documents)']}]}