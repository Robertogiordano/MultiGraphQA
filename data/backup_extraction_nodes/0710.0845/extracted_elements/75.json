[{'entity_name': 'Markov chain Monte Carlo', 'entity_type': 'Algorithm', 'entity_description': 'A statistical method used to approximate the posterior distribution of a model.', 'relationship': {'source_entity': 'Markov chain Monte Carlo', 'target_entity': 'hLDA', 'description': 'Used to approximate the posterior for.'}}, {'entity_name': 'hLDA', 'entity_type': 'Model', 'entity_description': 'Hierarchical Latent Dirichlet Allocation, a generative model for topic modeling.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'Markov chain Monte Carlo', 'description': 'Target of approximation by.'}}, {'entity_name': 'Robert and Casella', 'entity_type': 'Authors', 'entity_description': 'Researchers who contributed to the development of MCMC methods.', 'relationship': {'source_entity': 'Robert and Casella', 'target_entity': 'Markov chain Monte Carlo', 'description': 'Authored foundational work on.'}}, {'entity_name': 'latent topic structure', 'entity_type': 'Concept', 'entity_description': 'A theoretical framework for understanding the hidden structures in data, particularly in the context of document generation.', 'relationship': {'source_entity': 'latent topic structure', 'target_entity': 'observed documents', 'description': 'Is related to'}}, {'entity_name': 'observed documents', 'entity_type': 'Concept', 'entity_description': 'Documents that have been collected and analyzed to infer underlying structures.', 'relationship': {'source_entity': 'observed documents', 'target_entity': 'hidden structure', 'description': 'Conditioned on'}}, {'entity_name': 'hidden structure', 'entity_type': 'Concept', 'entity_description': 'The underlying topic structure that may have generated the observed documents.', 'relationship': {'source_entity': 'hidden structure', 'target_entity': 'data', 'description': 'Depends on'}}, {'entity_name': 'Bayesian statistics', 'entity_type': 'Field', 'entity_description': "A statistical paradigm that uses Bayes' theorem to update the probability of a hypothesis as more evidence becomes available.", 'relationship': {'source_entity': 'Bayesian statistics', 'target_entity': 'posterior distribution', 'description': 'Involves finding'}}, {'entity_name': 'posterior distribution', 'entity_type': 'Concept', 'entity_description': 'The distribution of the hidden structure after observing the data.', 'relationship': {'source_entity': 'posterior distribution', 'target_entity': 'data and models', 'description': 'Is found for'}}, {'entity_name': 'hLDA', 'entity_type': 'Model', 'entity_description': 'Hierarchical Latent Dirichlet Allocation, a statistical model for discovering and visualizing hierarchies in document collections.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'document collection', 'description': 'Analyzes to discover and visualize hierarchy.'}}, {'entity_name': 'hyperparameters', 'entity_type': 'Parameter', 'entity_description': 'Settings that influence the behavior of the hLDA model.', 'relationship': {'source_entity': 'hyperparameters', 'target_entity': 'goal of the analysis', 'description': 'Determines how they are set.'}}, {'entity_name': 'predictive model', 'entity_type': 'Model', 'entity_description': 'A model used to make predictions based on data.', 'relationship': {'source_entity': 'predictive model', 'target_entity': 'data', 'description': 'Used to compare hLDA to other statistical models.'}}, {'entity_name': 'Section 6.2', 'entity_type': 'Section', 'entity_description': 'A section in the document that discusses the analysis of documents.', 'relationship': {'source_entity': 'Section 6.2', 'target_entity': 'documents', 'description': 'Analyzes documents with a specific purpose.'}}, {'entity_name': 'Corpus', 'entity_type': 'Concept', 'entity_description': 'A collection of documents used for analysis.', 'relationship': {'source_entity': 'Corpus', 'target_entity': 'Probabilistic Model', 'description': 'Described by using a probabilistic model.'}}, {'entity_name': 'Probabilistic Model', 'entity_type': 'Model', 'entity_description': 'A statistical model that incorporates probabilities to describe data.', 'relationship': {'source_entity': 'Probabilistic Model', 'target_entity': 'Parameters', 'description': 'Involves a fixed set of parameters.'}}, {'entity_name': 'Parameters', 'entity_type': 'Concept', 'entity_description': 'Variables that define the behavior of the model.', 'relationship': {'source_entity': 'Parameters', 'target_entity': 'Documents', 'description': 'Can grow as the corpus grows.'}}, {'entity_name': 'Documents', 'entity_type': 'Concept', 'entity_description': 'Individual pieces of written content within the corpus.', 'relationship': {'source_entity': 'Documents', 'target_entity': 'Subtopics', 'description': 'Can spark new subtopics or specializations.'}}, {'entity_name': 'Subtopics', 'entity_type': 'Concept', 'entity_description': 'Specific themes or topics that arise within the corpus.', 'relationship': {'source_entity': 'Subtopics', 'target_entity': 'Approximate Posterior Inference', 'description': 'Allows discovery of the tree of topics.'}}, {'entity_name': 'Approximate Posterior Inference', 'entity_type': 'Method', 'entity_description': 'A statistical method used to estimate the distribution of parameters.', 'relationship': {'source_entity': 'Approximate Posterior Inference', 'target_entity': 'Tree of Topics', 'description': 'Used to discover the tree of topics that best describes documents.'}}, {'entity_name': 'Tree of Topics', 'entity_type': 'Concept', 'entity_description': 'A hierarchical representation of topics derived from the corpus.', 'relationship': {'source_entity': 'Tree of Topics', 'target_entity': 'Documents', 'description': 'Describes the documents.'}}, {'entity_name': 'document', 'entity_type': 'Concept', 'entity_description': 'A written or printed work that can originate from various topics.', 'relationship': {'source_entity': 'document', 'target_entity': 'topics', 'description': 'Can come from previously generated topics or new topics.'}}, {'entity_name': 'topics', 'entity_type': 'Concept', 'entity_description': 'Subjects or themes that documents can be generated from.', 'relationship': {'source_entity': 'topics', 'target_entity': 'document', 'description': 'Documents can be generated based on these topics.'}}, {'entity_name': 'ddocuments', 'entity_type': 'Concept', 'entity_description': 'A reference to previously generated documents.', 'relationship': {'source_entity': 'ddocuments', 'target_entity': 'document', 'description': 'The (d+1)th document can follow paths laid down by these earlier documents.'}}, {'entity_name': 'model', 'entity_type': 'Concept', 'entity_description': 'A nonparametric model used to describe a corpus.', 'relationship': {'source_entity': 'model', 'target_entity': 'corpus', 'description': 'Describes a corpus using a nonparametric approach.'}}, {'entity_name': 'corpus', 'entity_type': 'Concept', 'entity_description': 'A collection of written texts.', 'relationship': {'source_entity': 'corpus', 'target_entity': 'model', 'description': 'Is described by the model.'}}, {'entity_name': 'Dirichlet parameter', 'entity_type': 'Hyperparameter', 'entity_description': 'A parameter that controls the sparsity of the topics in a model.', 'relationship': {'source_entity': 'Dirichlet parameter', 'target_entity': 'topics', 'description': 'Affects the sparsity of the topics.'}}, {'entity_name': 'stick-breaking parameters', 'entity_type': 'Hyperparameter', 'entity_description': 'Parameters that influence the topic proportions in a model.', 'relationship': {'source_entity': 'stick-breaking parameters', 'target_entity': 'topic proportions', 'description': 'Affects the distribution of topic proportions.'}}, {'entity_name': 'topics', 'entity_type': 'Concept', 'entity_description': 'The subjects or themes identified in a model based on the Dirichlet parameter.', 'relationship': {'source_entity': 'topics', 'target_entity': 'words', 'description': 'Topics are represented by a set of words.'}}, {'entity_name': 'topic proportions', 'entity_type': 'Concept', 'entity_description': 'The distribution of topics within a document.', 'relationship': {'source_entity': 'topic proportions', 'target_entity': 'words', 'description': 'Determines how topics are represented by words.'}}, {'entity_name': 'Sanderson and Croft', 'entity_type': 'Authors', 'entity_description': 'Researchers who contributed to the field of text domains in 1999.', 'relationship': {'source_entity': 'Sanderson and Croft', 'target_entity': 'text domains', 'description': 'Conducted research on'}}, {'entity_name': 'Stoica and Hearst', 'entity_type': 'Authors', 'entity_description': 'Researchers who contributed to the field of text analysis in 2004.', 'relationship': {'source_entity': 'Stoica and Hearst', 'target_entity': 'text analysis', 'description': 'Conducted research on'}}, {'entity_name': 'Cimiano et al.', 'entity_type': 'Authors', 'entity_description': 'Researchers who contributed to the field of text analysis in 2005.', 'relationship': {'source_entity': 'Cimiano et al.', 'target_entity': 'text analysis', 'description': 'Conducted research on'}}, {'entity_name': 'hierarchy of topics', 'entity_type': 'Concept', 'entity_description': 'A structure that organizes topics based on their relationships and distributions over terms.', 'relationship': {'source_entity': 'hierarchy of topics', 'target_entity': 'text analysis', 'description': 'Used in the method for text analysis'}}, {'entity_name': 'topics', 'entity_type': 'Concept', 'entity_description': 'Distributions over terms that describe significant patterns of word co-occurrence in data.', 'relationship': {'source_entity': 'topics', 'target_entity': 'terms', 'description': 'Describes a distribution over'}}, {'entity_name': 'hLDA model', 'entity_type': 'Model', 'entity_description': 'A probabilistic model used for performing posterior inference to estimate the hidden topical structure of a document collection.', 'relationship': {'source_entity': 'hLDA model', 'target_entity': 'posterior inference', 'description': 'Used to perform'}}, {'entity_name': 'posterior inference', 'entity_type': 'Process', 'entity_description': 'The process of inverting the generative process of documents to estimate hidden structures.', 'relationship': {'source_entity': 'posterior inference', 'target_entity': 'latent topic structure', 'description': 'Estimates the hidden structure of'}}, {'entity_name': 'latent topic structure', 'entity_type': 'Concept', 'entity_description': 'The hidden structure representing topics within a document collection.', 'relationship': {'source_entity': 'latent topic structure', 'target_entity': 'observed documents', 'description': 'Combined with to form a joint distribution.'}}, {'entity_name': 'observed documents', 'entity_type': 'Data', 'entity_description': 'Documents that are analyzed to infer the latent topic structure.', 'relationship': {'source_entity': 'observed documents', 'target_entity': 'joint distribution', 'description': 'Combined with latent topic structure to form.'}}, {'entity_name': 'joint distribution', 'entity_type': 'Statistical Concept', 'entity_description': 'A distribution that combines hidden variables and observations.', 'relationship': {'source_entity': 'joint distribution', 'target_entity': 'hidden variables', 'description': 'Includes as part of its formulation.'}}, {'entity_name': 'hidden variables', 'entity_type': 'Concept', 'entity_description': 'Variables that are not directly observed but are inferred from the data.', 'relationship': {'source_entity': 'hidden variables', 'target_entity': 'observations', 'description': 'Related to in the context of probabilistic models.'}}, {'entity_name': 'probability mass', 'entity_type': 'Concept', 'entity_description': 'A measure of the likelihood of a set of words being chosen.', 'relationship': {'source_entity': 'probability mass', 'target_entity': 'words', 'description': 'Is concentrated on'}}, {'entity_name': 'prior bias', 'entity_type': 'Concept', 'entity_description': 'A tendency to favor sparser topics in the analysis.', 'relationship': {'source_entity': 'prior bias', 'target_entity': 'topics', 'description': 'Influences the preference for'}}, {'entity_name': 'posterior', 'entity_type': 'Concept', 'entity_description': 'The updated probability distribution after observing data.', 'relationship': {'source_entity': 'posterior', 'target_entity': 'topics', 'description': 'Prefers more topics to describe'}}, {'entity_name': 'stick-breaking parameters', 'entity_type': 'Concept', 'entity_description': 'Parameters that control the allocation of words to topics.', 'relationship': {'source_entity': 'stick-breaking parameters', 'target_entity': 'words', 'description': 'Determine likelihood of words coming from'}}, {'entity_name': 'abstraction levels', 'entity_type': 'Concept', 'entity_description': 'Different levels of generality in topic representation.', 'relationship': {'source_entity': 'abstraction levels', 'target_entity': 'words', 'description': 'Are associated with higher probability when set large'}}, {'entity_name': 'm', 'entity_type': 'Parameter', 'entity_description': 'A parameter that influences word allocation in documents.', 'relationship': {'source_entity': 'm', 'target_entity': 'word allocations', 'description': 'Affects the likelihood of deviation from'}}, {'entity_name': 'Bayesian statistics', 'entity_type': 'Field of Study', 'entity_description': "A statistical paradigm that involves using Bayes' theorem to update the probability of a hypothesis as more evidence becomes available.", 'relationship': {'source_entity': 'Bayesian statistics', 'target_entity': 'Bernardo and Smith (1994)', 'description': 'Cited as a general introduction to Bayesian statistics.'}}, {'entity_name': 'Bayesian statistics', 'entity_type': 'Field of Study', 'entity_description': "A statistical paradigm that involves using Bayes' theorem to update the probability of a hypothesis as more evidence becomes available.", 'relationship': {'source_entity': 'Bayesian statistics', 'target_entity': 'Gelman et al. (1995)', 'description': 'Cited as a general introduction to Bayesian statistics.'}}, {'entity_name': 'hLDA', 'entity_type': 'Model', 'entity_description': 'Hierarchical Latent Dirichlet Allocation, a generative model for topic modeling.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'posterior distribution', 'description': 'The posterior distribution for hLDA is not available in closed form.'}}, {'entity_name': 'documents', 'entity_type': 'Data', 'entity_description': 'A collection of written texts used for analysis in Bayesian statistics.', 'relationship': {'source_entity': 'documents', 'target_entity': 'posterior distribution', 'description': 'The posterior distribution is derived from a collection of documents.'}}, {'entity_name': 'computer', 'entity_type': 'Technology', 'entity_description': 'A device used to perform calculations and process data.', 'relationship': {'source_entity': 'computer', 'target_entity': 'finite resources', 'description': 'The analysis must be performed using the finite resources of the computer.'}}, {'entity_name': 'D. M. Blei', 'entity_type': 'Person', 'entity_description': 'A researcher in the field of topic modeling.', 'relationship': {'source_entity': 'D. M. Blei', 'target_entity': 'T. L. Griffiths', 'description': 'Collaborates with'}}, {'entity_name': 'T. L. Griffiths', 'entity_type': 'Person', 'entity_description': 'A researcher in the field of topic modeling.', 'relationship': {'source_entity': 'T. L. Griffiths', 'target_entity': 'M. I. Jordan', 'description': 'Collaborates with'}}, {'entity_name': 'M. I. Jordan', 'entity_type': 'Person', 'entity_description': 'A researcher in the field of statistics and machine learning.', 'relationship': {'source_entity': 'M. I. Jordan', 'target_entity': 'D. M. Blei', 'description': 'Collaborates with'}}, {'entity_name': 'dynamic topic model', 'entity_type': 'Model', 'entity_description': 'A topic model that incorporates time-stamped documents and evolving topics.', 'relationship': {'source_entity': 'dynamic topic model', 'target_entity': 'documents', 'description': 'Models'}}, {'entity_name': 'author-topic model', 'entity_type': 'Model', 'entity_description': 'A topic model that considers the authorship of documents.', 'relationship': {'source_entity': 'author-topic model', 'target_entity': 'authorship', 'description': 'Incorporates'}}, {'entity_name': 'documents', 'entity_type': 'Concept', 'entity_description': 'Written works that are analyzed in topic modeling.', 'relationship': {'source_entity': 'documents', 'target_entity': 'dynamic topic model', 'description': 'Used in'}}, {'entity_name': 'authorship', 'entity_type': 'Concept', 'entity_description': 'The identity of the author of a document.', 'relationship': {'source_entity': 'authorship', 'target_entity': 'author-topic model', 'description': 'Considered in'}}, {'entity_name': 'hLDA', 'entity_type': 'Model', 'entity_description': 'A statistical model used for topic modeling that exploits a nested Chinese Restaurant Process (CRP).', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'hyperparameters', 'description': 'Fits hyperparameters by placing priors and computing their posterior.'}}, {'entity_name': 'hyperparameters', 'entity_type': 'Parameter', 'entity_description': 'Parameters that are set prior to the model fitting process.', 'relationship': {'source_entity': 'hyperparameters', 'target_entity': 'posterior', 'description': 'Computed through posterior inference.'}}, {'entity_name': 'posterior', 'entity_type': 'Statistical Concept', 'entity_description': 'The updated probability of a parameter after considering new evidence.', 'relationship': {'source_entity': 'posterior', 'target_entity': 'Section 5.4', 'description': 'Described in Section 5.4.'}}, {'entity_name': 'documents', 'entity_type': 'Data', 'entity_description': 'Textual data analyzed using the hLDA approach.', 'relationship': {'source_entity': 'documents', 'target_entity': 'Section 6.3', 'description': 'Analyzed in Section 6.3.'}}, {'entity_name': 'nested CRP', 'entity_type': 'Statistical Process', 'entity_description': 'A flexible hierarchy of distributions used in topic modeling.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'nested CRP', 'description': 'Exploits the nested CRP.'}}, {'entity_name': 'variant of hLDA', 'entity_type': 'Model', 'entity_description': 'A more complicated version of hLDA that allows multiple paths through the tree for each document.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'variant of hLDA', 'description': 'Could consider a variant where each document exhibits multiple paths.'}}, {'entity_name': 'Pritchard et al.', 'entity_type': 'Researcher', 'entity_description': 'Authors of a study referenced in the context of flat topic models.', 'relationship': {'source_entity': 'Pritchard et al.', 'target_entity': 'flat topic models', 'description': 'Demonstrated applications in the context of flat topic models.'}}, {'entity_name': 'Marlin', 'entity_type': 'Researcher', 'entity_description': 'Author of a study referenced in the context of flat topic models.', 'relationship': {'source_entity': 'Marlin', 'target_entity': 'flat topic models', 'description': 'Demonstrated applications in the context of flat topic models.'}}, {'entity_name': 'Fei-Fei and Perona', 'entity_type': 'Researcher', 'entity_description': 'Authors of a study referenced in the context of flat topic models.', 'relationship': {'source_entity': 'Fei-Fei and Perona', 'target_entity': 'flat topic models', 'description': 'Demonstrated applications in the context of flat topic models.'}}, {'entity_name': 'Blei and Jordan', 'entity_type': 'Researcher', 'entity_description': 'Authors of a study referenced in the context of flat topic models.', 'relationship': {'source_entity': 'Blei and Jordan', 'target_entity': 'flat topic models', 'description': 'Demonstrated applications in the context of flat topic models.'}}, {'entity_name': 'Airoldi et al.', 'entity_type': 'Researcher', 'entity_description': 'Authors of a study referenced in the context of flat topic models.', 'relationship': {'source_entity': 'Airoldi et al.', 'target_entity': 'flat topic models', 'description': 'Demonstrated applications in the context of flat topic models.'}}, {'entity_name': 'Bayesian nonparametric model', 'entity_type': 'Model', 'entity_description': 'A statistical model that can accommodate future data.', 'relationship': {'source_entity': 'Bayesian nonparametric model', 'target_entity': 'future data', 'description': 'Can accommodate future data that might lie in new and previously undiscovered distributions.'}}, {'entity_name': 'Lafferty', 'entity_type': 'Person', 'entity_description': 'An author referenced in the context of topic modeling.', 'relationship': {'source_entity': 'Lafferty', 'target_entity': 'Blei', 'description': 'Collaborated on research related to topic modeling.'}}, {'entity_name': 'Rosen-Zvi', 'entity_type': 'Person', 'entity_description': 'An author referenced in the context of the author-topic model.', 'relationship': {'source_entity': 'Rosen-Zvi', 'target_entity': 'Lafferty', 'description': 'Contributed to the development of the author-topic model.'}}, {'entity_name': 'Blei', 'entity_type': 'Person', 'entity_description': 'An author referenced in the context of topic modeling.', 'relationship': {'source_entity': 'Blei', 'target_entity': 'Lafferty', 'description': 'Collaborated on research related to topic modeling.'}}, {'entity_name': 'correlated topic model', 'entity_type': 'Model', 'entity_description': 'A model that exhibits a covariance structure in topic proportions.', 'relationship': {'source_entity': 'correlated topic model', 'target_entity': 'Dirichlet distribution', 'description': 'Replaces Dirichlet distribution with a logistic normal.'}}, {'entity_name': 'Bayesian nonparametric extensions', 'entity_type': 'Concept', 'entity_description': 'Extensions in Bayesian statistics that are less direct in application.', 'relationship': {'source_entity': 'Bayesian nonparametric extensions', 'target_entity': 'correlated topic model', 'description': 'Applied in the context of the correlated topic model.'}}, {'entity_name': 'hLDA', 'entity_type': 'Algorithm', 'entity_description': 'Hierarchical Latent Dirichlet Allocation, a generative model for topic modeling.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'D. M. BLEI', 'description': 'Developed by'}}, {'entity_name': 'D. M. BLEI', 'entity_type': 'Person', 'entity_description': 'A researcher known for contributions to machine learning and statistics.', 'relationship': {'source_entity': 'D. M. BLEI', 'target_entity': 'T. L. GRIFFITHS', 'description': 'Collaborated with'}}, {'entity_name': 'T. L. GRIFFITHS', 'entity_type': 'Person', 'entity_description': 'A researcher in the field of machine learning and statistics.', 'relationship': {'source_entity': 'T. L. GRIFFITHS', 'target_entity': 'M. I. JORDAN', 'description': 'Collaborated with'}}, {'entity_name': 'M. I. JORDAN', 'entity_type': 'Person', 'entity_description': 'A prominent figure in machine learning and statistics.', 'relationship': {'source_entity': 'M. I. JORDAN', 'target_entity': 'hLDA', 'description': 'Contributed to the development of'}}, {'entity_name': 'zd;n', 'entity_type': 'Variable', 'entity_description': 'Denotes the level allocations in document d, leaving out zd;n.', 'relationship': {'source_entity': 'zd;n', 'target_entity': 'document d', 'description': 'Represents level allocations in the document.'}}, {'entity_name': 'Eq. (2)', 'entity_type': 'Equation', 'entity_description': 'An equation referenced in the text.', 'relationship': {'source_entity': 'Eq. (2)', 'target_entity': 'distribution over levels', 'description': 'Defines a distribution over levels.'}}, {'entity_name': 'D. M. BLEI', 'entity_type': 'Person', 'entity_description': 'An author mentioned in the text.', 'relationship': {'source_entity': 'D. M. BLEI', 'target_entity': 'T. L. GRIFFITHS', 'description': 'Co-author.'}}, {'entity_name': 'T. L. GRIFFITHS', 'entity_type': 'Person', 'entity_description': 'An author mentioned in the text.', 'relationship': {'source_entity': 'T. L. GRIFFITHS', 'target_entity': 'M. I. JORDAN', 'description': 'Co-author.'}}, {'entity_name': 'M. I. JORDAN', 'entity_type': 'Person', 'entity_description': 'An author mentioned in the text.', 'relationship': {'source_entity': 'M. I. JORDAN', 'target_entity': 'D. M. BLEI', 'description': 'Co-author.'}}, {'entity_name': 'Gibbs sampler', 'entity_type': 'Algorithm', 'entity_description': 'A statistical method used for sampling from probability distributions based on constructing a Markov chain.', 'relationship': {'source_entity': 'Gibbs sampler', 'target_entity': 'latent variable', 'description': 'Samples iteratively conditioned on observations and other latent variables.'}}, {'entity_name': 'collapsed Gibbs sampling', 'entity_type': 'Algorithm', 'entity_description': 'An adaptation of Gibbs sampling that marginalizes out some latent variables to improve convergence speed.', 'relationship': {'source_entity': 'collapsed Gibbs sampling', 'target_entity': 'latent variables', 'description': 'Marginalizes out some latent variables.'}}, {'entity_name': 'Liu, 1994', 'entity_type': 'Publication', 'entity_description': 'A reference to a work by Liu that discusses collapsed Gibbs sampling.', 'relationship': {'source_entity': 'collapsed Gibbs sampling', 'target_entity': 'Liu, 1994', 'description': 'Introduced the concept of collapsed Gibbs sampling.'}}, {'entity_name': 'Grifﬁths and Steyvers, 2004', 'entity_type': 'Publication', 'entity_description': 'A reference to a work that applies collapsed Gibbs sampling to topic models.', 'relationship': {'source_entity': 'collapsed Gibbs sampling', 'target_entity': 'Grifﬁths and Steyvers, 2004', 'description': 'Applied collapsed Gibbs sampling to topic models.'}}, {'entity_name': 'topic modeling applications', 'entity_type': 'Field', 'entity_description': 'Applications that utilize topic modeling techniques to analyze text data.', 'relationship': {'source_entity': 'collapsed Gibbs sampling', 'target_entity': 'topic modeling applications', 'description': 'Has been widely used in.'}}, {'entity_name': 'McCallum et al., 2004', 'entity_type': 'Publication', 'entity_description': 'A reference to a work that discusses topic modeling applications.', 'relationship': {'source_entity': 'topic modeling applications', 'target_entity': 'McCallum et al., 2004', 'description': 'Discusses the use of topic modeling.'}}, {'entity_name': 'hLDA', 'entity_type': 'Algorithm', 'entity_description': 'Hierarchical Latent Dirichlet Allocation, a model for topic modeling that incorporates hierarchical structures.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'per-document paths', 'description': 'Samples the per-document paths.'}}, {'entity_name': 'per-document paths', 'entity_type': 'Concept', 'entity_description': 'Paths that represent the structure of topics within documents in hLDA.', 'relationship': {'source_entity': 'hLDA', 'target_entity': 'per-word level', 'description': 'Relates to the per-word level sampling.'}}, {'entity_name': 'CRP parameter', 'entity_type': 'Parameter', 'entity_description': 'A parameter that controls the size of the inferred tree in topic modeling.', 'relationship': {'source_entity': 'CRP parameter', 'target_entity': 'inferred tree', 'description': 'Controls the size of.'}}, {'entity_name': 'topic prior', 'entity_type': 'Parameter', 'entity_description': 'A parameter that influences the allocation of topics within a document.', 'relationship': {'source_entity': 'topic prior', 'target_entity': 'inferred tree', 'description': 'Provides control over the size of.'}}, {'entity_name': 'hyperparameters', 'entity_type': 'Parameter', 'entity_description': 'Settings that can be fixed or inferred based on analysis constraints and prior expectations.', 'relationship': {'source_entity': 'hyperparameters', 'target_entity': 'analysis', 'description': 'Can be fixed according to the constraints of.'}}, {'entity_name': 'latent variable models', 'entity_type': 'Model', 'entity_description': 'Statistical models that include variables that are not directly observed but are inferred from other variables that are observed.', 'relationship': {'source_entity': 'latent variable models', 'target_entity': 'Markov chain', 'description': 'Utilizes the state space of the Markov chain to represent the values of latent variables.'}}, {'entity_name': 'Markov chain', 'entity_type': 'Mathematical Concept', 'entity_description': 'A stochastic process that undergoes transitions from one state to another on a state space.', 'relationship': {'source_entity': 'Markov chain', 'target_entity': 'latent variables', 'description': 'Defines the state space for the values that latent variables can take.'}}, {'entity_name': 'target distribution', 'entity_type': 'Statistical Concept', 'entity_description': 'The distribution that we aim to estimate, which is conditional on observed data.', 'relationship': {'source_entity': 'target distribution', 'target_entity': 'latent variables', 'description': 'Is the conditional distribution of latent variables given the observed data.'}}, {'entity_name': 'Gibbs sampling algorithm', 'entity_type': 'Algorithm', 'entity_description': 'A Markov Chain Monte Carlo (MCMC) algorithm used for sampling from a multivariate probability distribution.', 'relationship': {'source_entity': 'Gibbs sampling algorithm', 'target_entity': 'latent variables', 'description': 'Samples each latent variable iteratively conditioned on the others.'}}, {'entity_name': 'Geman and Geman', 'entity_type': 'Authors', 'entity_description': 'Researchers known for their work on Gibbs sampling.', 'relationship': {'source_entity': 'Geman and Geman', 'target_entity': 'Gibbs sampling algorithm', 'description': 'Developed the Gibbs sampling algorithm in 1984.'}}, {'entity_name': 'Gelfand and Smith', 'entity_type': 'Authors', 'entity_description': 'Researchers known for their contributions to Bayesian statistics and MCMC methods.', 'relationship': {'source_entity': 'Gelfand and Smith', 'target_entity': 'Gibbs sampling algorithm', 'description': 'Contributed to the development of the Gibbs sampling algorithm in 1990.'}}, {'entity_name': 'tree', 'entity_type': 'Concept', 'entity_description': 'A structure that organizes topics in a hierarchical manner.', 'relationship': {'source_entity': 'tree', 'target_entity': 'topics', 'description': 'Contains'}}, {'entity_name': 'topics', 'entity_type': 'Concept', 'entity_description': 'Subjects or themes that are represented in the tree structure.', 'relationship': {'source_entity': 'topics', 'target_entity': 'words', 'description': 'Associated with'}}, {'entity_name': 'words', 'entity_type': 'Concept', 'entity_description': 'Units of language that convey meaning and are used in the context of topics.', 'relationship': {'source_entity': 'words', 'target_entity': 'data', 'description': 'Explains'}}, {'entity_name': 'posterior', 'entity_type': 'Concept', 'entity_description': 'A statistical term referring to the updated probability after considering new evidence.', 'relationship': {'source_entity': 'posterior', 'target_entity': 'data', 'description': 'Requires'}}, {'entity_name': 'nested CRP', 'entity_type': 'Concept', 'entity_description': 'A model that allows for the creation of clusters in a hierarchical manner.', 'relationship': {'source_entity': 'nested CRP', 'target_entity': 'documents', 'description': 'Influences'}}, {'entity_name': 'GEM parameter m', 'entity_type': 'Parameter', 'entity_description': 'A parameter that reflects the proportion of general words relative to specific words.', 'relationship': {'source_entity': 'GEM parameter m', 'target_entity': 'general words', 'description': 'Reflects'}}, {'entity_name': 'GEM parameter ɣ', 'entity_type': 'Parameter', 'entity_description': 'A parameter that indicates how strictly documents adhere to the proportions of general and specific words.', 'relationship': {'source_entity': 'GEM parameter ɣ', 'target_entity': 'documents', 'description': 'Enforces'}}, {'entity_name': 'generality and specificity', 'entity_type': 'Concept', 'entity_description': 'Concepts that describe the level of generality or specificity in the context of words.', 'relationship': {'source_entity': 'generality and specificity', 'target_entity': 'trees', 'description': 'Lead to'}}, {'entity_name': 'Gibbs sampler', 'entity_type': 'Algorithm', 'entity_description': 'A statistical sampling algorithm used for obtaining a sequence of observations approximated from a specified multivariate probability distribution.', 'relationship': {'source_entity': 'Gibbs sampler', 'target_entity': 'maximum-flow problem', 'description': 'Used to analyze the problem.'}}, {'entity_name': 'maximum-flow problem', 'entity_type': 'Problem', 'entity_description': 'A classic problem in network flow theory that aims to find the maximum flow from a source to a sink in a flow network.', 'relationship': {'source_entity': 'maximum-flow problem', 'target_entity': 'Goldberg and Tarjan', 'description': 'Proposed a new approach to.'}}, {'entity_name': 'Goldberg and Tarjan', 'entity_type': 'Authors', 'entity_description': 'Researchers who authored the paper on a new approach to the maximum-flow problem.', 'relationship': {'source_entity': 'Goldberg and Tarjan', 'target_entity': 'document', 'description': 'Authored the document.'}}, {'entity_name': 'document', 'entity_type': 'Document', 'entity_description': 'The written work associated with the maximum-flow problem.', 'relationship': {'source_entity': 'document', 'target_entity': 'hierarchy', 'description': 'Is associated with a path through.'}}, {'entity_name': 'hierarchy', 'entity_type': 'Structure', 'entity_description': 'A structured representation of nodes associated with distributions over terms.', 'relationship': {'source_entity': 'hierarchy', 'target_entity': 'terms', 'description': 'Each node is associated with a distribution over.'}}, {'entity_name': 'terms', 'entity_type': 'Concept', 'entity_description': 'Words or phrases that are relevant to the document.', 'relationship': {'source_entity': 'terms', 'target_entity': 'words', 'description': 'Each word is associated with a level in the hierarchy.'}}, {'entity_name': 'words', 'entity_type': 'Words', 'entity_description': 'Individual units of language used in the abstract.', 'relationship': {'source_entity': 'words', 'target_entity': 'path', 'description': 'Associated with a level in the path through the hierarchy.'}}, {'entity_name': 'path', 'entity_type': 'Path', 'entity_description': 'A sequence through the hierarchy indicating levels of terms.', 'relationship': {'source_entity': 'path', 'target_entity': 'Gibbs sampler', 'description': 'Iteratively draws levels for all words.'}}, {'entity_name': 'zd;n', 'entity_type': 'Variable', 'entity_description': 'The level allocation variable for word n in document d.', 'relationship': {'source_entity': 'zd;n', 'target_entity': 'wd;n', 'description': 'Is sampled from its distribution given other variables.'}}, {'entity_name': 'wd;n', 'entity_type': 'Variable', 'entity_description': 'The observed word variable for word n in document d.', 'relationship': {'source_entity': 'wd;n', 'target_entity': 'zd;n', 'description': 'Is sampled from its distribution given other variables.'}}, {'entity_name': 'document d', 'entity_type': 'Document', 'entity_description': 'A document containing words and their level allocations.', 'relationship': {'source_entity': 'document d', 'target_entity': 'zd;n', 'description': 'Contains the level allocation variable for word n.'}}, {'entity_name': 'c', 'entity_type': 'Parameter', 'entity_description': 'A parameter influencing the distribution of level allocations.', 'relationship': {'source_entity': 'c', 'target_entity': 'zd;n', 'description': 'Affects the sampling of the level allocation variable.'}}, {'entity_name': 'w', 'entity_type': 'Parameter', 'entity_description': 'A parameter representing the observed words.', 'relationship': {'source_entity': 'w', 'target_entity': 'wd;n', 'description': 'Affects the sampling of the observed word variable.'}}, {'entity_name': 'm', 'entity_type': 'Parameter', 'entity_description': 'A parameter involved in the distribution of level allocations.', 'relationship': {'source_entity': 'm', 'target_entity': 'zd;n', 'description': 'Affects the sampling of the level allocation variable.'}}, {'entity_name': 'z(d;n)', 'entity_type': 'Vector', 'entity_description': 'The vector of level allocations excluding zd;n.', 'relationship': {'source_entity': 'z(d;n)', 'target_entity': 'zd;n', 'description': 'Used in the calculation of the distribution for sampling.'}}, {'entity_name': 'w(d;n)', 'entity_type': 'Vector', 'entity_description': 'The vector of observed words excluding wd;n.', 'relationship': {'source_entity': 'w(d;n)', 'target_entity': 'wd;n', 'description': 'Used in the calculation of the distribution for sampling.'}}, {'entity_name': 'Koller and Sahami', 'entity_type': 'Researchers', 'entity_description': 'Authors of a study on algorithms for document categorization.', 'relationship': {'source_entity': 'Koller and Sahami', 'target_entity': 'document categories', 'description': 'Developed methods for placing documents within a hierarchy.'}}, {'entity_name': 'Chakrabarti et al.', 'entity_type': 'Researchers', 'entity_description': 'Authors of a study related to text data analysis.', 'relationship': {'source_entity': 'Chakrabarti et al.', 'target_entity': 'document categories', 'description': 'Contributed to methods for categorizing documents.'}}, {'entity_name': 'McCallum et al.', 'entity_type': 'Researchers', 'entity_description': 'Authors of a study on text categorization algorithms.', 'relationship': {'source_entity': 'McCallum et al.', 'target_entity': 'document categories', 'description': 'Worked on algorithms for placing documents in hierarchies.'}}, {'entity_name': 'Dumais and Chen', 'entity_type': 'Researchers', 'entity_description': 'Authors who researched document categorization methods.', 'relationship': {'source_entity': 'Dumais and Chen', 'target_entity': 'document categories', 'description': 'Developed methods for categorizing documents.'}}, {'entity_name': 'Sanderson and Croft', 'entity_type': 'Researchers', 'entity_description': 'Authors who focused on deriving hierarchies of terms.', 'relationship': {'source_entity': 'Sanderson and Croft', 'target_entity': 'individual terms', 'description': 'Derived hierarchies using side information.'}}, {'entity_name': 'Stoica', 'entity_type': 'Researcher', 'entity_description': 'A researcher involved in text analysis.', 'relationship': {'source_entity': 'Stoica', 'target_entity': 'individual terms', 'description': 'Contributed to deriving hierarchies of terms.'}}, {'entity_name': 'Markov chain', 'entity_type': 'Concept', 'entity_description': 'A mathematical system that undergoes transitions from one state to another on a state space.', 'relationship': {'source_entity': 'Markov chain', 'target_entity': 'hLDA model', 'description': 'Illustrates the process of approximating the posterior.'}}, {'entity_name': 'hLDA model', 'entity_type': 'Model', 'entity_description': 'Hierarchical Latent Dirichlet Allocation model used for topic modeling.', 'relationship': {'source_entity': 'hLDA model', 'target_entity': 'JACM', 'description': 'Conditioned on abstracts from the JACM.'}}, {'entity_name': 'JACM', 'entity_type': 'Publication', 'entity_description': 'Journal of the Association for Computing Machinery, a scholarly journal.', 'relationship': {'source_entity': 'JACM', 'target_entity': 'abstracts', 'description': 'Provides abstracts used in the hLDA model.'}}, {'entity_name': 'hyperparameter', 'entity_type': 'Parameter', 'entity_description': 'A parameter whose value is set before the learning process begins.', 'relationship': {'source_entity': 'hyperparameter', 'target_entity': 'customers', 'description': 'Reflects the tendency of the customers in each restaurant to share tables.'}}, {'entity_name': 'customers', 'entity_type': 'Group', 'entity_description': 'Individuals who dine at the restaurant.', 'relationship': {'source_entity': 'customers', 'target_entity': 'tables', 'description': 'Share tables in the restaurant.'}}, {'entity_name': 'variance', 'entity_type': 'Statistical Measure', 'entity_description': 'A measure of how much values in a dataset differ from the mean.', 'relationship': {'source_entity': 'variance', 'target_entity': 'underlying topics', 'description': 'Reflects the expected variance of the underlying topics.'}}, {'entity_name': 'topics', 'entity_type': 'Concept', 'entity_description': 'Subjects or themes that are discussed in a document.', 'relationship': {'source_entity': 'topics', 'target_entity': 'high-probability words', 'description': 'Topics with fewer high-probability words are chosen.'}}]