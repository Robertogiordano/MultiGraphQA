{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ridefinizione del Progetto**\n",
    "\n",
    "Il progetto si evolve in una pipeline duale che combina due approcci distinti per l'elaborazione di documenti scientifici su ArXiv, uno focalizzato sull'information retrieval multimodale per il QA e l'altro orientato alla creazione e utilizzo di un grafo per il reasoning avanzato. Ecco una sintesi della nuova struttura:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Obiettivo Generale**\n",
    "Creare un Google Colab notebook che esplora due metodi distinti:\n",
    "1. **Approccio Multimodale per il QA**: Retrieval di contenuti (testo e visivi) da documenti ArXiv con valutazione quantitativa delle prestazioni su un task di multiple-choice QA.\n",
    "2. **GraphRAG per Reasoning Avanzato**: Creazione e utilizzo di un grafo di conoscenza a partire da documenti ArXiv per rispondere a domande complesse (multi-hop reasoning e aggregazioni) attraverso tecnologie avanzate.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Descrizione dei Due Moduli**\n",
    "\n",
    "#### **Modulo 1: Approccio Multimodale per QA**\n",
    "- **Focus**: Estrarre chunk di testo e figure dai PDF, utilizzarli in pipeline di retrieval (multimodale e text-only), e valutarli quantitativamente in un task di QA multiple-choice.\n",
    "- **Tecnologie**:\n",
    "  - Modelli multimodali (es. ColQwen2).\n",
    "  - Late interaction per text-only retrieval.\n",
    "  - Metriche di valutazione come Precision@k, MRR e accuratezza downstream su QA.\n",
    "- **Output**:\n",
    "  - Risultati numerici sulle prestazioni dei vari approcci.\n",
    "  - Tabelle e grafici comparativi.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Modulo 2: GraphRAG per Reasoning Avanzato**\n",
    "- **Focus**: Costruire un grafo di conoscenza a partire dai documenti ArXiv (estrazione di entità e relazioni) per rispondere a domande complesse.\n",
    "- **Pipeline**:\n",
    "  1. **Estrazione di Entità e Relazioni**:\n",
    "     - Uso di LLM (es. GPT-4o-mini) per identificare nodi e archi, con varianti per aggiungere forza relazionale o descrizioni.\n",
    "  2. **Popolazione del Grafo**:\n",
    "     - Archiviazione in un database Neo4j per interrogazioni successive.\n",
    "  3. **Interrogazione del Grafo**:\n",
    "     - Approcci:\n",
    "       - Vicini diretti di entità.\n",
    "       - Community detection e clustering.\n",
    "       - Generazione di query Cypher con un LLM.\n",
    "  4. **Reasoning e Risposta**:\n",
    "     - Generazione di risposte condizionate da cluster di entità.\n",
    "     - Combina risposte locali e globali con pesi stimati.\n",
    "- **Tecnologie**:\n",
    "  - **Neo4j** per graphDB.\n",
    "  - **Milvus** per indicizzazione come VectorDB.\n",
    "  - **LangGraph** per pipeline automatizzata.\n",
    "- **Output**:\n",
    "  - Demo interattiva con domande esempio.\n",
    "  - Visualizzazioni di query sul grafo e risposte.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Struttura del Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 1: Multimodal Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Setup**: Installazione di librerie e caricamento dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      @misc{li2024multimodal,\n",
    "            title={Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models}, \n",
    "            author={Lei Li and Yuqi Wang and Runxin Xu and Peiyi Wang and Xiachong Feng and Lingpeng Kong and Qi Liu},\n",
    "            year={2024},\n",
    "            eprint={2403.00231},\n",
    "            archivePrefix={arXiv},\n",
    "            primaryClass={cs.CV}\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parquet files inside folder data\n",
    "ds = load_dataset('parquet', data_files='data/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'image', 'image_filename', 'options', 'answer', 'page', 'model', 'prompt', 'source'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Based on the graph, what is the impact of correcting for fspec not equal to 1 on the surface density trend?',\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1621x1191>,\n",
       " 'image_filename': 'images/1810.10511_2.jpg',\n",
       " 'options': \"['A. Correction causes a significant increase in surface density across all radii.', 'B. Correction results in a decrease in surface density for larger radii.', 'C. Correction causes the surface density to converge with the fspec = 1 case at larger radii.', 'D. Correction does not affect the surface density trend at all.', '-']\",\n",
       " 'answer': 'C',\n",
       " 'page': '',\n",
       " 'model': 'gpt4V',\n",
       " 'prompt': '',\n",
       " 'source': 'arxiv_qa'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "read",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Image\u001b[38;5;241m.\u001b[39mopen(ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/MultiGraphQA/.conda/lib/python3.11/site-packages/PIL/Image.py:3480\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3478\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3480\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m   3482\u001b[0m preinit()\n\u001b[1;32m   3484\u001b[0m warning_messages: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/MultiGraphQA/.conda/lib/python3.11/site-packages/PIL/JpegImagePlugin.py:396\u001b[0m, in \u001b[0;36mJpegImageFile.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    394\u001b[0m     deprecate(name, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name)\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: read"
     ]
    }
   ],
   "source": [
    "Image.open(ds['train'][0]['image']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>image</th>\n",
       "      <th>image_filename</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>page</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the graph, what is the impact of corr...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>images/1810.10511_2.jpg</td>\n",
       "      <td>['A. Correction causes a significant increase ...</td>\n",
       "      <td>C</td>\n",
       "      <td></td>\n",
       "      <td>gpt4V</td>\n",
       "      <td></td>\n",
       "      <td>arxiv_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on the progression from JUL10 to FEB11Q,...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>images/1107.3275_2.jpg</td>\n",
       "      <td>['A) A consistent decrease in the percentage o...</td>\n",
       "      <td>D</td>\n",
       "      <td></td>\n",
       "      <td>gpt4V</td>\n",
       "      <td></td>\n",
       "      <td>arxiv_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What physical phenomenon could the pattern of ...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>images/quant-ph9912091_0.jpg</td>\n",
       "      <td>['A. Diffraction patterns of light', 'B. Magne...</td>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td>gpt4V</td>\n",
       "      <td></td>\n",
       "      <td>arxiv_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the approximate uv-distance where the ...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>images/1808.10438_2.jpg</td>\n",
       "      <td>['A) 0 - 500 kλ', 'B) 500 - 1000 kλ', 'C) 1000...</td>\n",
       "      <td>B</td>\n",
       "      <td></td>\n",
       "      <td>gpt4V</td>\n",
       "      <td></td>\n",
       "      <td>arxiv_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which subfigures does the average arrival f...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>images/cond-mat0603861_2.jpg</td>\n",
       "      <td>['A) Subfigures (a) and (b)', 'B) Subfigures (...</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "      <td>gpt4V</td>\n",
       "      <td></td>\n",
       "      <td>arxiv_qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Based on the graph, what is the impact of corr...   \n",
       "1  Based on the progression from JUL10 to FEB11Q,...   \n",
       "2  What physical phenomenon could the pattern of ...   \n",
       "3  What is the approximate uv-distance where the ...   \n",
       "4  In which subfigures does the average arrival f...   \n",
       "\n",
       "                                               image  \\\n",
       "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "\n",
       "                 image_filename  \\\n",
       "0       images/1810.10511_2.jpg   \n",
       "1        images/1107.3275_2.jpg   \n",
       "2  images/quant-ph9912091_0.jpg   \n",
       "3       images/1808.10438_2.jpg   \n",
       "4  images/cond-mat0603861_2.jpg   \n",
       "\n",
       "                                             options answer page  model  \\\n",
       "0  ['A. Correction causes a significant increase ...      C       gpt4V   \n",
       "1  ['A) A consistent decrease in the percentage o...      D       gpt4V   \n",
       "2  ['A. Diffraction patterns of light', 'B. Magne...      B       gpt4V   \n",
       "3  ['A) 0 - 500 kλ', 'B) 500 - 1000 kλ', 'C) 1000...      B       gpt4V   \n",
       "4  ['A) Subfigures (a) and (b)', 'B) Subfigures (...      A       gpt4V   \n",
       "\n",
       "  prompt    source  \n",
       "0         arxiv_qa  \n",
       "1         arxiv_qa  \n",
       "2         arxiv_qa  \n",
       "3         arxiv_qa  \n",
       "4         arxiv_qa  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Estrazione Contenuti**: Testo e immagini da documenti ArXiv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. **Implementazione Approcci**:\n",
    "   - Multimodale con modelli avanzati.\n",
    "   - Text-only con late interaction e late chunking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Pipeline di QA**: Risoluzione multiple-choice con un modello generativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Valutazione**:\n",
    "   - Metriche di retrieval.\n",
    "   - Accuratezza su QA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Visualizzazione**: Risultati e grafici comparativi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 2: GraphRAG**\n",
    "1. **Setup**: Installazione librerie (Neo4j, Milvus, LangGraph).\n",
    "2. **Estrazione Triple**:\n",
    "   - LLM per nodi e archi.\n",
    "   - Scelta tra aggiunta di forza relazionale o descrizioni.\n",
    "3. **Costruzione del Grafo**:\n",
    "   - Inserimento in Neo4j.\n",
    "4. **Interrogazione e Reasoning**:\n",
    "   - Community detection, vicini diretti, query Cypher.\n",
    "   - Generazione risposte locali e globali.\n",
    "5. **Demo Interattiva**:\n",
    "   - Domande multi-hop con risposte strutturate.\n",
    "6. **Visualizzazione**:\n",
    "   - Visualizzazione del grafo e delle risposte.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **4. Output Finale**\n",
    "- **Modulo 1**: Report quantitativo sulle prestazioni dei modelli di retrieval nel task multimodale.\n",
    "- **Modulo 2**: Grafo di conoscenza interattivo con risposte a domande complessive e reasoning complesso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
